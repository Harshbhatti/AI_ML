{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bde75fa-dd99-4da0-8aec-961f2e2e8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚ú® Welcome to the AI Story Generator! ‚ú®\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What should your story be about? (e.g., 'A young wizard finds a magic book'):  An amateur treasure hunter stumbles upon a map that leads to a lost city of gold, but they‚Äôre not the only one searching for it.\n",
      "\n",
      "How many words should the story be (approx.)? (e.g., 100):  500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåü Generating your story... Please wait! üåü\n",
      "\n",
      "Here‚Äôs your story:\n",
      "\n",
      "==================================================\n",
      "An amateur treasure hunter stumbles upon a map that leads to a lost city of gold, but they‚Äôre not the only one searching for it. An amateur treasure hunter stumbles upon a map that leads to a lost city of gold, but they‚Äôre not the only one searching for it.\n",
      "\n",
      "What happens next in the story? The most interesting and suspenseful part is this chapter: you get your first glimpse at some major characters or events from other areas which make up Chapter 10 ‚Äì What Happens Next!\n",
      "\n",
      " (1) A new group called 'The Red Horse' finds their place on Earth as an adventurer by rescuing two young ladies who have been abducted while trying out various quests together; then all sorts about how those girls got trapped within these caves‚Ä¶ And finally finding them...and discovering exactly where everything went wrong when someone stole away more than once before‚Äîthe adventure begins with Beryl & Hina getting into trouble soon after taking off along different paths through several kingdoms including Darkshire.. Meanwhile Princess Luna arrives across Fairyland City telling everyone what happened last night. But Riku just can't seem fazed anymore‚Äìor so he thinks‚Ä¶.. In fact its almost like nothing will come true until Fili discovers something hidden inside Lidlithium Island : I see‚Ä¶. But Riku just can't seem fazed anymore‚Äìor so he thinks‚Ä¶.. In fact its almost like nothing will come true until Fili discovers something hidden inside Lidlith's coffin‚Ä¶. But Riku just can't seem fazed anymore‚Äìor so he thinks‚Ä¶.. In fact its almost like nothing will come true until Fili discovers something hidden inside Lidlitha's heart‚Ä¶. But Riku just can't seem fazed anymore‚Äìor so he thinks‚Ä¶.. They were both captured during her attack against Lady Moltron , even though she was clearly innocent!! Now there are five people still under investigation because every time Gogwyr comes back looking serious we lose our minds over whether Zephaniah had anything better done !!! I think if anyone wanted another game experience without any action plot elements maybe Yudongo would play around too much instead ;) So be sure check my reviews post #9. But Riku just can't seem fazed anymore‚Äìor so he thinks‚Ä¶.. She asks him if she was really going there alone because otherwise her soul would be stolen without warning ‚Ä¶ Now imagine having no idea why anyone ever did anything such cruel thing could happen‚Ä¶‚Ä¶ It feels very odd seeing Asuna back home during Eris Festival weekend though I'm sure many people were hoping much further ahead due solely being tired/mildly anxious afterwards knowing things had gotten worse suddenly right now since we weren¬¥t actually doing any real work here yet. That mysterious power being stored deep beneath her has turned evil again‚Ä¶‚Ä¶ She decides she wants revenge because no-one would ever take advantage if there was such thing. In fact its almost like nothing will come true until Fili discovers something hidden inside Lidlith's skull‚Ä¶.\n",
      "==================================================\n",
      "\n",
      "üîç Relevance to prompt: 86.58%\n",
      "üìä Word Count (Story): 488\n",
      "\n",
      "üåü Thank you for using the AI Story Generator! üåü\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set pad token to avoid attention mask issues\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load a lightweight SentenceTransformer model for semantic similarity\n",
    "semantic_model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def generate_story_chunk(prompt, max_new_tokens=150, temperature=0.8, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Generates a chunk of the story based on the given prompt.\n",
    "    \"\"\"\n",
    "    input_data = tokenizer.encode_plus(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    input_ids = input_data[\"input_ids\"].to(device)\n",
    "    attention_mask = input_data[\"attention_mask\"].to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.8,\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "def remove_repetition(text, all_previous_chunks, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Removes repetitive or semantically similar sentences based on similarity.\n",
    "    \"\"\"\n",
    "    sentences = text.split(\". \")\n",
    "    filtered_sentences = []\n",
    "    sentence_embeddings = semantic_model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    for i, sentence_embedding in enumerate(sentence_embeddings):\n",
    "        is_similar = False\n",
    "\n",
    "        for prev_chunk in all_previous_chunks:\n",
    "            chunk_embedding = semantic_model.encode(prev_chunk, convert_to_tensor=True)\n",
    "            if util.cos_sim(sentence_embedding, chunk_embedding).item() > similarity_threshold:\n",
    "                is_similar = True\n",
    "                break\n",
    "\n",
    "        if not is_similar:\n",
    "            filtered_sentences.append(sentences[i].strip())\n",
    "\n",
    "    return \". \".join(filtered_sentences).strip()\n",
    "\n",
    "def clean_story_ending(text):\n",
    "    \"\"\"\n",
    "    Cleans the story ending by removing incomplete trailing sentences.\n",
    "    \"\"\"\n",
    "    sentences = text.split(\". \")\n",
    "    if sentences[-1] and not sentences[-1].endswith(\".\"):\n",
    "        return \". \".join(sentences[:-1]).strip() + \".\"\n",
    "    return text.strip()\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Counts the number of words in a given text.\n",
    "    \"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "def build_story(prompt, word_count=500):\n",
    "    \"\"\"\n",
    "    Builds the story in chunks, ensuring reduced repetition and coherence.\n",
    "    \"\"\"\n",
    "    max_new_tokens = 150\n",
    "    current_story = prompt\n",
    "    all_previous_chunks = [prompt]\n",
    "    iteration_limit = 25\n",
    "    iterations = 0\n",
    "\n",
    "    while count_words(current_story) < word_count and iterations < iteration_limit:\n",
    "        iterations += 1\n",
    "        remaining_words = word_count - count_words(current_story)\n",
    "\n",
    "        # Expand prompt for richer context\n",
    "        extended_prompt = f\"{current_story}\\n\\nWhat happens next in the story?\"\n",
    "        chunk = generate_story_chunk(\n",
    "            extended_prompt, max_new_tokens=min(max_new_tokens, remaining_words * 2)\n",
    "        )\n",
    "\n",
    "        # Filter repetitive or semantically similar sentences\n",
    "        filtered_chunk = remove_repetition(chunk, all_previous_chunks)\n",
    "        cleaned_chunk = clean_story_ending(filtered_chunk)\n",
    "\n",
    "        # Append valid chunk to the story\n",
    "        if count_words(cleaned_chunk) > 5 and cleaned_chunk not in all_previous_chunks:\n",
    "            current_story += \" \" + cleaned_chunk\n",
    "            all_previous_chunks.append(cleaned_chunk)\n",
    "\n",
    "    return current_story.strip()\n",
    "\n",
    "def evaluate_story(prompt, story):\n",
    "    \"\"\"\n",
    "    Evaluates the semantic similarity between the prompt and story.\n",
    "    \"\"\"\n",
    "    prompt_embedding = semantic_model.encode(prompt, convert_to_tensor=True)\n",
    "    story_embedding = semantic_model.encode(story, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(prompt_embedding, story_embedding).item()\n",
    "    return similarity * 100\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to handle user input and generate a story.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚ú® Welcome to the AI Story Generator! ‚ú®\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    prompt = input(\"\\nWhat should your story be about? (e.g., 'A young wizard finds a magic book'): \").strip()\n",
    "    if not prompt:\n",
    "        print(\"‚ö†Ô∏è Please enter a valid story idea.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        word_count = int(input(\"\\nHow many words should the story be (approx.)? (e.g., 100): \").strip())\n",
    "    except ValueError:\n",
    "        print(\"‚ö†Ô∏è Invalid input. Using default length of 150 words.\")\n",
    "        word_count = 150\n",
    "\n",
    "    print(\"\\nüåü Generating your story... Please wait! üåü\")\n",
    "    story = build_story(prompt, word_count=word_count)\n",
    "    relevance_score = evaluate_story(prompt, story)\n",
    "\n",
    "    print(\"\\nHere‚Äôs your story:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(story)\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nüîç Relevance to prompt: {relevance_score:.2f}%\")\n",
    "    print(f\"üìä Word Count (Story): {count_words(story)}\")\n",
    "    print(\"\\nüåü Thank you for using the AI Story Generator! üåü\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad1443-812b-459c-95b6-b8cdf68f3331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
